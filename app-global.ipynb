{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gp\n",
    "from branca.colormap import linear\n",
    "from bokeh.models import ColumnDataSource, GeoJSONDataSource, ColorBar, HoverTool, Legend, LogColorMapper\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models import CustomJS, Select, MultiSelect, Plot, LinearAxis, Range1d, DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Line, MultiLine\n",
    "from bokeh.palettes import Set1\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import datetime as dt\n",
    "pn.extension()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping a page to find the link to the latest weekly data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url, tag, extension):\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    tags = BeautifulSoup(page, 'html.parser')(tag)\n",
    "    for t in tags:\n",
    "        href = t.get('href', '')\n",
    "        if href[-len(extension):] == extension:\n",
    "            return href\n",
    "    return ''\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and clean global epidemic data and calculate totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clean(url, filename):\n",
    "    data = pd.read_excel(url + filename)\n",
    "    data.countriesAndTerritories = data.countriesAndTerritories.str.replace('_', ' ')\n",
    "    data.dateRep = pd.to_datetime(data.dateRep, infer_datetime_format=True)\n",
    "    data = data.sort_values(['countriesAndTerritories', 'dateRep'])\n",
    "    data['total cases'] = data.groupby(['countriesAndTerritories']).cases.apply(lambda x: x.cumsum())\n",
    "    data['total deaths'] = data.groupby(['countriesAndTerritories']).deaths.apply(lambda x: x.cumsum())\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read geographic data for the map and trim to Hungary \n",
    "eu = gp.read_file('https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_10M_2021_4326_LEVL_3.geojson')\n",
    "country = 'HU'\n",
    "geo = eu.loc[eu['CNTR_CODE'] == country].sort_values('id')\n",
    "# Read worldwide daily epidemic data\n",
    "url = 'https://www.ecdc.europa.eu/sites/default/files/documents/'\n",
    "excel = 'COVID-19-geographic-disbtribution-worldwide.xlsx'\n",
    "world = read_clean(url, excel)\n",
    "# Find and get weekly regional data\n",
    "link = scrape(url='https://www.ecdc.europa.eu/en/publications-data/weekly-subnational-14-day-notification-rate-covid-19', tag='a', extension='xlsx')\n",
    "sub = pd.read_excel(link)\n",
    "sub.drop(sub[sub['nuts_code'].str[:2] != country].index, inplace=True)\n",
    "# List of region codes in the country\n",
    "nuts = list(sub.nuts_code.value_counts().index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series of the selected countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_countries(event):\n",
    "    countries = country_select.value[:10]\n",
    "    value = chart_select.value\n",
    "    colors = Set1[9]\n",
    "    items = []\n",
    "    datasource = ColumnDataSource(pd.pivot_table(world, index='dateRep', columns='countriesAndTerritories', values=value).reset_index())        \n",
    "    c = 0   \n",
    "    chart = figure(plot_width=600, plot_height=600, x_axis_type='datetime', y_axis_type='linear', tools=[])        \n",
    "    for country in countries:\n",
    "        g = chart.add_glyph(datasource, Line(x='dateRep', y=country, line_color=colors[c], line_width=3, line_alpha=.8, name=country))\n",
    "        c += 1\n",
    "        items.append((country, [g]))\n",
    "    chart.xaxis.axis_label = 'Date'\n",
    "    first = dt.datetime(2020, 3, 1).date()\n",
    "    today = dt.datetime.now().date()\n",
    "    chart.xaxis.fixed_location = 0\n",
    "    #chart.xaxis.ticker=DaysTicker(days=np.arange(1, ((np.datetime64(today) - np.datetime64(first)) / np.timedelta64(1, 'D')).astype(int), 15), num_minor_ticks=3)\n",
    "    chart.x_range = Range1d(start=np.datetime64(first), end=np.datetime64(today)) \n",
    "    chart.yaxis.axis_label = value        \n",
    "    chart.add_layout(Legend(location='top_left', items=items))    \n",
    "    chart.background_fill_color = 'ghostwhite'\n",
    "    chart.background_fill_alpha = 0.5\n",
    "    chart.legend.label_text_font_size = '8pt'\n",
    "    chart.toolbar.logo = None\n",
    "    chart_pane.object = chart\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map():\n",
    "    m = folium.Map(location=[48,19], zoom_start=7.5, tiles=None, overlay=False)\n",
    "    # The Folium map contains one layer for each of the last 20 weeks\n",
    "    start = int(sub.year_week.max()[-2:]) - 19\n",
    "    weeks = len(sub.loc[sub['year_week'].str[-2:].ge(str(start))].sort_values('nuts_code').year_week.unique())\n",
    "    for i in range(weeks):\n",
    "        choropleth1 = folium.Choropleth(\n",
    "            geo_data=geo,\n",
    "            name='choropleth',\n",
    "            data=sub.loc[sub['year_week'].str[-2:].eq(str(i + start))],\n",
    "            columns=['nuts_code', 'rate_14_day_per_100k'],\n",
    "            key_on='feature.properties.id',\n",
    "            fill_color='Greys',\n",
    "            fill_opacity=0.7,\n",
    "            line_opacity=0.2,\n",
    "            highlight=True,\n",
    "            line_color='black',\n",
    "            bins=list(sub.loc[sub['year_week'].str[-2:].eq(str(i + start))].rate_14_day_per_100k.quantile([0, 0.05, 0.1, 0.2, 0.4, 0.6, 0.75, 0.9, 1]))\n",
    "        ).geojson.add_to(\n",
    "            folium.FeatureGroup(\n",
    "                overlay=False, name='Week '+str(i + start)).add_to(m))\n",
    "\n",
    "        for c in range(0, len(nuts)):\n",
    "            point = geo[geo.values[:, 0] == nuts[c]].geometry.representative_point()\n",
    "            # For every region we draw a circle with a radius according to the data represented\n",
    "            folium.Circle(\n",
    "                location=[point.y, point.x],\n",
    "                geo_data=geo,\n",
    "                radius=float(sub.loc[(sub['nuts_code'] == nuts[c]) & (sub['year_week'].str[-2:].eq(str(i + start)))].rate_14_day_per_100k*50),\n",
    "                color='crimson',\n",
    "                fill=True,\n",
    "                fill_color='blue').add_to([fs for key, fs in m._children.items()][i])\n",
    "        # Tooltip with the regions' names\n",
    "        geojson1 = folium.GeoJson(data=geo, tooltip=folium.features.GeoJsonTooltip(['NUTS_NAME'], labels=False), style_function=lambda x: {'color':'black','fillColor':'transparent','weight':0.5},\n",
    "    ).add_to(choropleth1)\n",
    "    # Adding a layer control to choose from weekly maps\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    # m.save('map.html')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Panel dashboard: a chart with two selectors, and an independent choropleth map of Hungarian regional data\n",
    "countries = list(world.countriesAndTerritories.unique())\n",
    "top_countries = ['China','United Kingdom','United States of America','Spain','Italy','France','Iran','Australia','Brazil','Sweden','Russia','India']\n",
    "country_select = pnw.MultiSelect(name='Country', value=top_countries[:3], height=150, options=countries, width=150)\n",
    "country_select.param.watch(chart_countries, 'value')\n",
    "chart_select = pnw.Select(name='Chart of', value='cases', options=['cases','deaths','total cases','total deaths'], width=150)\n",
    "chart_select.param.watch(chart_countries, 'value')\n",
    "title = pn.pane.HTML('<h2>Coronavirus plots</h2>')\n",
    "chart_pane = pn.pane.Bokeh()\n",
    "chart = chart_countries(None)\n",
    "mp = plot_map()\n",
    "map_pane = pn.pane.plot.Folium(mp)\n",
    "app = pn.Column(pn.Row(pn.Column(title, country_select, chart_select), pn.Spacer(min_width=250), chart_pane),\n",
    "              pn.pane.HTML('<h2>New cases in Hungary per 100 000 population by week</h2>'), map_pane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
